# 决策树（上）：经历两个阶段，分别是构造和剪枝
# 构造过程中的三个节点：根节点、内部节点、叶节点
# 剪枝：防止“过拟合”现象发生。分为预剪枝和后剪枝

# 选择将哪个属性作为根节点是个关键问题——纯度和信息熵

# 决策树的构造过程理解为寻找纯净划分的过程。即，让目标变量的分歧最小
'''
经典“不纯度”指标有三种：
信息增益（ID3算法）；信息增益率（C4.5算法）；基尼指数（Cart算法）
ID3和C4.5可以生成二叉树或多叉树；CART只支持二叉树

CART既可以作为分类树，又可以作为回归树
分类树是在类别中做出选择；回归树是对连续性数值进行预测
属性选择的指标采用基尼系数。基尼系数本身反映样本的不确定度。

ID3将信息增益最大的节点作为父节点，这样可以得到纯度高的决策树。
'''



'''
#使用ID3算法解决问题
from sklearn import tree
import graphviz
import numpy as np
import os
os.environ["PATH"] += os.pathsep + 'D:\python3.7\graphviz-2.38\release\bin'

# 创建数据【红，大】，1==是，0==否
data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])
# 数据标注为，1==好苹果，0==坏苹果
target = np.array([1, 1, 0, 0])

clf = tree.DecisionTreeClassifier()  # 创建决策树分类器模型
clf = clf.fit(data, target)  # 拟合数据

# 利用graphviz打印出决策树图
dot_data = tree.export_graphviz(clf, out_file=None)
graph = graphviz.Source(dot_data)
graph.render("tree")
print(graph)
'''



'''
#利用CART分类树，给iris数据集构造一棵分类决策树
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
import graphviz
from sklearn.tree import export_graphviz
#准备数据集
iris = load_iris()
#获取特征集和分类标识
features = iris.data
labels = iris.target
#随机抽取33%的数据作为测试集，其余作为训练集
train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size=0.33,random_state=0)
#创建CART分类树
clf = DecisionTreeClassifier(criterion='gini')
#拟合构造CART分类树
clf = clf.fit(train_features,train_labels)
#用CART分类树做预测
test_predict = clf.predict(test_features)
#预测结果与测试集结果作比对
score = accuracy_score(test_labels,test_predict)
dot_data = export_graphviz(clf,out_file=None)
graph = graphviz.Source(dot_data)
graph.render("tree1")
print("CART分类树准确率 %.4lf" % score)
'''


'''
#可视化过程
import graphviz
from sklearn.tree import export_graphviz
dot_data = export_graphviz(clf,out_file=None)  #参数是分类树/回归树模型的名称，不输出文件
graph = graphviz.Source(dot_data)
graph.render("tree1")
'''



'''
#利用CART回归树，给波士顿房价做预测
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import load_boston
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error

import graphviz
from sklearn.tree import export_graphviz
#准备数据集
boston = load_boston()
#探索数据
print(boston.feature_names)
#获取特征集和房价
features = boston.data
prices = boston.target
#随机抽取33%的数据作为测试集，其余作为训练集
train_features,test_features,train_price,test_price = train_test_split(features,prices,test_size=0.33)
#创建CART回归树
dtr = DecisionTreeRegressor()
#拟合构造CART回归树
dtr.fit(train_features,train_price)
#预测测试集中的房价
predict_price = dtr.predict(test_features)
#测试集中的结果评价
print("回归树二乘偏差均值：",mean_squared_error(test_price,predict_price))
print("回归树绝对值偏差均值：",mean_absolute_error(test_price,predict_price))
dot_data = export_graphviz(dtr,out_file=None)  #参数是分类树/回归树模型的名称，不输出文件
graph = graphviz.Source(dot_data)
graph.render("boston")
'''



'''
#创建一个CART分类树，对手写数据集做分类。另外选取一部分测试集用来统计分类树的准确率
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_digits
import graphviz
from sklearn.tree import export_graphviz
#准备数据集
digit = load_digits()
#获取特征集和分类标识
features = digit.data
labels = digit.target
#随机抽取33%的数据作为测试集，其余作为训练集
train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size=0.33,random_state=0)
#创建CART分类树
clf = DecisionTreeClassifier(criterion='gini')
#拟合构造CART分类树
clf = clf.fit(train_features,train_labels)
#用CART分类树做预测
test_predict = clf.predict(test_features)
#预测结果与测试集结果作比对
score = accuracy_score(test_labels,test_predict)
print("CART分类树准确率: %.4lf" % score)
dot_data = export_graphviz(clf,out_file=None)  #参数是分类树/回归树模型的名称，不输出文件
graph = graphviz.Source(dot_data)
graph.render("digit")
'''

#基于决策树，产生了“随机森林”
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import DecisionTreeClassifier
import graphviz
from sklearn.tree import export_graphviz

# 数据加载
train_data = pd.read_csv('./train.csv')
test_data = pd.read_csv('./test.csv')
# 数据探索
print(train_data.info())  #了解数据表基本状况：行数、列数、每列的数据类型、数据完整度
print(test_data.info())
print('-'*30)
print(train_data.describe())   #数据表的统计情况——总数、平均值、标准差、最小值、最大值等
print('-'*30)
print(train_data.describe(include=['O']))   #查看字符串类型的整体情况
print('-'*30)
print(train_data.head())   #查看前几行数据，默认为前5行
print('-'*30)
print(train_data.tail())  #查看后几行数据，默认为后5行

#数据清洗
# 使用平均年龄来填充年龄中的 nan 值
train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)
test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)
# 使用票价的均值填充票价中的 nan 值
train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)
test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)
print(train_data['Embarked'].value_counts())
# 使用登录最多的港口来填充登录港口的 nan 值
train_data['Embarked'].fillna('S', inplace=True)
test_data['Embarked'].fillna('S',inplace=True)

# 特征选择
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
train_features = train_data[features]
train_labels = train_data['Survived']
test_features = test_data[features]
dvec = DictVectorizer(sparse=False)
train_features = dvec.fit_transform(train_features.to_dict(orient='record'))
print(dvec.feature_names_)

#构造 ID3 决策树
clf = DecisionTreeClassifier(criterion='entropy')
# 决策树训练
clf.fit(train_features, train_labels)

test_features = dvec.transform(test_features.to_dict(orient='record'))
# 决策树预测
pred_labels = clf.predict(test_features)

# 得到决策树准确率
acc_decision_tree = round(clf.score(train_features, train_labels), 6)
print(u'score 准确率为 %.4lf' % acc_decision_tree)
dot_data = export_graphviz(clf,out_file=None)  #参数是分类树/回归树模型的名称，不输出文件
graph = graphviz.Source(dot_data)
graph.render("titanic")
